#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIæ–‡çŒ®åˆ†æå™¨æ ¸å¿ƒç±»
é‡æ„ç‰ˆæœ¬ - æ”¯æŒé…ç½®æ–‡ä»¶å’Œè‡ªå®šä¹‰æ¨¡æ¿

Copyright (c) 2024 Yudong Fang (yudongfang55@gmail.com)
Licensed under the MIT License. See LICENSE file for details.
"""

import os
import json
import re
import requests
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Any
import PyPDF2
import pdfplumber
import logging

from .config_manager import ConfigManager


class AILiteratureAnalyzer:
    """AIé©±åŠ¨çš„æ–‡çŒ®åˆ†æå™¨"""
    
    def __init__(self, config_manager: ConfigManager):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            config_manager: é…ç½®ç®¡ç†å™¨å®ä¾‹
        """
        self.config = config_manager
        
        # è·å–é…ç½®
        api_config = self.config.get_api_config()
        paths_config = self.config.get_paths_config()
        
        # APIé…ç½®
        self.api_key = api_config['api_key']
        self.api_base = api_config['base_url']
        self.model = api_config['model']
        self.timeout = api_config['timeout']
        self.max_retries = api_config['max_retries']
        self.retry_delay = api_config['retry_delay']
        self.temperature = api_config['temperature']
        self.max_tokens = api_config['max_tokens']
        
        # è·¯å¾„é…ç½®
        self.input_dir = Path(paths_config['input_dir'])
        self.output_dir = Path(paths_config['output_dir'])
        self.summaries_dir = Path(paths_config['summaries_dir'])
        self.method_cards_dir = Path(paths_config['method_cards_dir'])
        self.batch_reports_dir = Path(paths_config['batch_reports_dir'])
        
        # å¤„ç†é…ç½®
        processing_config = self.config.get_processing_config()
        self.max_text_length = processing_config['max_text_length']
        self.extract_pages = processing_config['extract_pages']
        self.skip_analyzed = processing_config['skip_analyzed']
        
        # åˆ›å»ºå¿…è¦ç›®å½•
        self.config.create_directories()
        
        # è®¾ç½®æ—¥å¿—
        self._setup_logging()
        
        # åŠ è½½æç¤ºè¯æ¨¡æ¿
        self.analysis_template = self.config.load_prompt_template('analysis')
        self.method_card_template = self.config.load_prompt_template('method_card')
        
        self.logger.info(f"AIæ–‡çŒ®åˆ†æç³»ç»Ÿå·²å¯åŠ¨")
        self.logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.model}")
        self.logger.info(f"è¾“å…¥ç›®å½•: {self.input_dir}")
        self.logger.info(f"è¾“å‡ºç›®å½•: {self.output_dir}")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging_config = self.config.get_logging_config()
        
        # åˆ›å»ºlogger
        self.logger = logging.getLogger('AILiteratureAnalyzer')
        self.logger.setLevel(getattr(logging, logging_config.get('level', 'INFO')))
        
        # æ¸…é™¤å·²æœ‰çš„å¤„ç†å™¨
        self.logger.handlers.clear()
        
        # æ–‡ä»¶å¤„ç†å™¨
        paths_config = self.config.get_paths_config()
        log_file = paths_config.get('log_file')
        if log_file:
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setLevel(logging.DEBUG)
            formatter = logging.Formatter(logging_config.get('format', 
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        if logging_config.get('console_output', True):
            console_handler = logging.StreamHandler()
            console_handler.setLevel(getattr(logging, logging_config.get('level', 'INFO')))
            formatter = logging.Formatter('%(levelname)s - %(message)s')
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
    
    def extract_pdf_text(self, pdf_path: Path) -> str:
        """ä»PDFæå–æ–‡æœ¬"""
        text = ""
        
        try:
            # é¦–å…ˆå°è¯•pdfplumberï¼ˆæ›´ç²¾ç¡®ï¼‰
            with pdfplumber.open(pdf_path) as pdf:
                pages_to_extract = len(pdf.pages)
                if self.extract_pages > 0:
                    pages_to_extract = min(self.extract_pages, len(pdf.pages))
                
                for i in range(pages_to_extract):
                    page_text = pdf.pages[i].extract_text()
                    if page_text:
                        text += page_text + "\n"
                        
            if not text.strip():
                raise Exception("pdfplumberæœªæå–åˆ°æ–‡æœ¬")
                
        except Exception as e:
            self.logger.warning(f"pdfplumberå¤±è´¥ï¼Œå°è¯•PyPDF2: {e}")
            try:
                with open(pdf_path, 'rb') as file:
                    pdf_reader = PyPDF2.PdfReader(file)
                    pages_to_extract = len(pdf_reader.pages)
                    if self.extract_pages > 0:
                        pages_to_extract = min(self.extract_pages, len(pdf_reader.pages))
                    
                    for i in range(pages_to_extract):
                        text += pdf_reader.pages[i].extract_text() + "\n"
            except Exception as e2:
                self.logger.error(f"PDFæ–‡æœ¬æå–å®Œå…¨å¤±è´¥: {e2}")
                return ""
        
        return text.strip()
    
    def call_ai_api(self, messages: List[Dict[str, str]]) -> str:
        """è°ƒç”¨AI API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": messages,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens
        }
        
        for attempt in range(self.max_retries):
            try:
                self.logger.info(f"APIè°ƒç”¨å°è¯• {attempt + 1}/{self.max_retries}")
                response = requests.post(
                    f"{self.api_base}/chat/completions",
                    headers=headers,
                    json=data,
                    timeout=self.timeout
                )
                
                if response.status_code == 200:
                    result = response.json()
                    return result["choices"][0]["message"]["content"]
                else:
                    self.logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    self.logger.error(f"é”™è¯¯ä¿¡æ¯: {response.text}")
                    if attempt < self.max_retries - 1:
                        self.logger.info(f"ç­‰å¾…{self.retry_delay}ç§’åé‡è¯•...")
                        time.sleep(self.retry_delay)
                    continue
                    
            except Exception as e:
                self.logger.error(f"APIè°ƒç”¨å¼‚å¸¸ (å°è¯• {attempt + 1}): {e}")
                if attempt < self.max_retries - 1:
                    self.logger.info(f"ç­‰å¾…{self.retry_delay}ç§’åé‡è¯•...")
                    time.sleep(self.retry_delay)
                continue
        
        self.logger.error("æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†")
        return ""
    
    def analyze_paper_with_ai(self, pdf_text: str, pdf_filename: str) -> Dict[str, Any]:
        """ä½¿ç”¨AIåˆ†æè®ºæ–‡"""
        self.logger.info("æ­£åœ¨è¿›è¡ŒAIæ·±åº¦åˆ†æ...")
        
        # é™åˆ¶æ–‡æœ¬é•¿åº¦
        content = pdf_text[:self.max_text_length]
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = self.analysis_template.format(
            filename=pdf_filename,
            content=content
        )
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ¨¡å‹è½»é‡åŒ–é¢†åŸŸçš„ä¸“å®¶ï¼Œä¸“é—¨åˆ†ææ·±åº¦å­¦ä¹ æ¨¡å‹å‹ç¼©å’Œä¼˜åŒ–ç›¸å…³çš„å­¦æœ¯è®ºæ–‡ã€‚ä½ çš„åˆ†ææ·±å…¥ã€å®¢è§‚ã€ä¸“ä¸šã€‚"},
            {"role": "user", "content": analysis_prompt}
        ]
        
        ai_response = self.call_ai_api(messages)
        
        if not ai_response:
            return {"error": "AIåˆ†æå¤±è´¥"}
        
        return {"analysis": ai_response, "success": True}
    
    def generate_method_card_with_ai(self, analysis: str, pdf_filename: str) -> str:
        """ä½¿ç”¨AIç”Ÿæˆæ–¹æ³•å¡ç‰‡"""
        self.logger.info("ç”Ÿæˆæ–¹æ³•å¡ç‰‡...")
        
        method_prompt = self.method_card_template.format(analysis=analysis)
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ–‡æ¡£ä¸“å®¶ï¼Œä¸“é—¨ç”Ÿæˆæ¸…æ™°ç®€æ´çš„æŠ€æœ¯æ–¹æ³•å¡ç‰‡ã€‚"},
            {"role": "user", "content": method_prompt}
        ]
        
        return self.call_ai_api(messages)
    
    def is_already_analyzed(self, pdf_path: Path) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²ç»åˆ†æè¿‡"""
        if not self.skip_analyzed:
            return False
        
        safe_name = self._safe_filename(pdf_path.stem)
        output_config = self.config.get_output_config()
        suffix = output_config['summary_suffix']
        
        analysis_file = self.summaries_dir / f"{safe_name}{suffix}.md"
        return analysis_file.exists()
    
    def analyze_single_paper(self, pdf_path: Path) -> Dict[str, Any]:
        """åˆ†æå•ç¯‡è®ºæ–‡"""
        self.logger.info(f"å¼€å§‹åˆ†æ: {pdf_path.name}")
        
        # æ£€æŸ¥æ˜¯å¦å·²åˆ†æ
        if self.is_already_analyzed(pdf_path):
            self.logger.info(f"è·³è¿‡å·²åˆ†æçš„æ–‡ä»¶: {pdf_path.name}")
            return {"skipped": True, "file": pdf_path.name}
        
        # æå–PDFæ–‡æœ¬
        pdf_text = self.extract_pdf_text(pdf_path)
        if not pdf_text:
            self.logger.error("PDFæ–‡æœ¬æå–å¤±è´¥")
            return {"error": "æ–‡æœ¬æå–å¤±è´¥", "file": pdf_path.name}
        
        self.logger.info(f"æ–‡æœ¬æå–æˆåŠŸï¼Œé•¿åº¦: {len(pdf_text)} å­—ç¬¦")
        
        # AIåˆ†æ
        analysis_result = self.analyze_paper_with_ai(pdf_text, pdf_path.name)
        if "error" in analysis_result:
            self.logger.error("AIåˆ†æå¤±è´¥")
            return analysis_result
        
        # ç”Ÿæˆæ–¹æ³•å¡ç‰‡
        method_card = self.generate_method_card_with_ai(analysis_result["analysis"], pdf_path.name)
        
        # ä¿å­˜ç»“æœ
        result = {
            "file_path": str(pdf_path),
            "analysis": analysis_result["analysis"],
            "method_card": method_card,
            "analysis_date": datetime.now().isoformat(),
            "success": True
        }
        
        # ä¿å­˜åˆ†ææŠ¥å‘Š
        self._save_analysis_report(pdf_path, result)
        
        # ä¿å­˜æ–¹æ³•å¡ç‰‡
        self._save_method_card(pdf_path, method_card)
        
        self.logger.info(f"åˆ†æå®Œæˆ: {pdf_path.name}")
        return result
    
    def _save_analysis_report(self, pdf_path: Path, result: Dict[str, Any]):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        safe_name = self._safe_filename(pdf_path.stem)
        output_config = self.config.get_output_config()
        suffix = output_config['summary_suffix']
        
        report_path = self.summaries_dir / f"{safe_name}{suffix}.md"
        
        # æ„å»ºå†…å®¹
        content_parts = [f"# {pdf_path.name} - AIæ·±åº¦åˆ†æ"]
        
        if output_config.get('include_metadata', True):
            content_parts.extend([
                "",
                f"**åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                f"**ä½¿ç”¨æ¨¡å‹**: {self.model}",
                f"**åŸå§‹æ–‡ä»¶**: {pdf_path.name}",
                ""
            ])
        
        content_parts.extend([
            "---",
            "",
            result['analysis'],
            "",
            "---",
            "",
            "*æœ¬åˆ†æç”±AIç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*"
        ])
        
        content = "\n".join(content_parts)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.logger.info(f"åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")
    
    def _save_method_card(self, pdf_path: Path, method_card: str):
        """ä¿å­˜æ–¹æ³•å¡ç‰‡"""
        safe_name = self._safe_filename(pdf_path.stem)
        output_config = self.config.get_output_config()
        suffix = output_config['method_card_suffix']
        
        card_path = self.method_cards_dir / f"{safe_name}{suffix}.md"
        
        # æ„å»ºå†…å®¹
        content_parts = [f"# {pdf_path.name} - æ–¹æ³•å¡ç‰‡"]
        
        if output_config.get('include_metadata', True):
            content_parts.extend([
                "",
                f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
                f"**åŸå§‹æ–‡ä»¶**: {pdf_path.name}",
                ""
            ])
        
        content_parts.extend([
            "---",
            "",
            method_card,
            "",
            "---",
            "",
            "*æœ¬å¡ç‰‡ç”±AIç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*"
        ])
        
        content = "\n".join(content_parts)
        
        with open(card_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.logger.info(f"æ–¹æ³•å¡ç‰‡å·²ä¿å­˜: {card_path.name}")
    
    def _safe_filename(self, filename: str) -> str:
        """ç”Ÿæˆå®‰å…¨çš„æ–‡ä»¶å"""
        safe_name = re.sub(r'[<>:"/\\|?*]', '', filename)
        safe_name = re.sub(r'\s+', '_', safe_name)
        return safe_name[:50]  # é™åˆ¶é•¿åº¦
    
    def batch_analyze_papers(self, max_papers: int = None) -> Dict[str, Any]:
        """æ‰¹é‡åˆ†æè®ºæ–‡"""
        pdf_files = list(self.input_dir.glob("*.pdf"))
        
        if max_papers:
            pdf_files = pdf_files[:max_papers]
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æï¼Œå…± {len(pdf_files)} ç¯‡è®ºæ–‡")
        
        results = {
            "total_papers": len(pdf_files),
            "successful": 0,
            "failed": 0,
            "skipped": 0,
            "results": [],
            "start_time": datetime.now().isoformat()
        }
        
        for i, pdf_path in enumerate(pdf_files, 1):
            self.logger.info(f"--- å¤„ç† {i}/{len(pdf_files)} ---")
            
            try:
                result = self.analyze_single_paper(pdf_path)
                if result.get("success"):
                    results["successful"] += 1
                elif result.get("skipped"):
                    results["skipped"] += 1
                else:
                    results["failed"] += 1
                results["results"].append(result)
                
            except Exception as e:
                self.logger.error(f"å¤„ç† {pdf_path.name} æ—¶å‡ºé”™: {e}")
                results["failed"] += 1
                results["results"].append({
                    "error": str(e),
                    "file": pdf_path.name
                })
        
        results["end_time"] = datetime.now().isoformat()
        
        # ç”Ÿæˆæ‰¹é‡åˆ†ææŠ¥å‘Š
        self._save_batch_report(results)
        
        self.logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼")
        self.logger.info(f"æˆåŠŸ: {results['successful']} ç¯‡")
        self.logger.info(f"è·³è¿‡: {results['skipped']} ç¯‡") 
        self.logger.info(f"å¤±è´¥: {results['failed']} ç¯‡")
        
        return results
    
    def _save_batch_report(self, results: Dict[str, Any]):
        """ä¿å­˜æ‰¹é‡åˆ†ææŠ¥å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_path = self.batch_reports_dir / f"ai_batch_analysis_{timestamp}.md"
        
        success_rate = (results["successful"] / results["total_papers"] * 100) if results["total_papers"] > 0 else 0
        
        content = f"""# AIé©±åŠ¨æ‰¹é‡æ–‡çŒ®åˆ†ææŠ¥å‘Š

## ğŸ“Š åˆ†æç»Ÿè®¡

- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ä½¿ç”¨æ¨¡å‹**: {self.model}
- **æ€»è®ºæ–‡æ•°**: {results["total_papers"]}
- **æˆåŠŸåˆ†æ**: {results["successful"]} ç¯‡
- **è·³è¿‡æ–‡ä»¶**: {results["skipped"]} ç¯‡
- **åˆ†æå¤±è´¥**: {results["failed"]} ç¯‡
- **æˆåŠŸç‡**: {success_rate:.1f}%

## ğŸ“‹ åˆ†æè¯¦æƒ…

"""
        
        # æˆåŠŸçš„åˆ†æ
        successful_papers = [r for r in results["results"] if r.get("success")]
        if successful_papers:
            content += "### âœ… æˆåŠŸåˆ†æçš„è®ºæ–‡\n\n"
            for i, result in enumerate(successful_papers, 1):
                filename = Path(result["file_path"]).name
                content += f"{i}. **{filename}**\n"
            content += "\n"
        
        # è·³è¿‡çš„åˆ†æ
        skipped_papers = [r for r in results["results"] if r.get("skipped")]
        if skipped_papers:
            content += "### â­ï¸ è·³è¿‡çš„è®ºæ–‡\n\n"
            for i, result in enumerate(skipped_papers, 1):
                filename = result.get("file", "æœªçŸ¥æ–‡ä»¶")
                content += f"{i}. **{filename}** - å·²å­˜åœ¨åˆ†æç»“æœ\n"
            content += "\n"
        
        # å¤±è´¥çš„åˆ†æ
        failed_papers = [r for r in results["results"] if not r.get("success") and not r.get("skipped")]
        if failed_papers:
            content += "### âŒ åˆ†æå¤±è´¥çš„è®ºæ–‡\n\n"
            for i, result in enumerate(failed_papers, 1):
                filename = result.get("file", "æœªçŸ¥æ–‡ä»¶")
                error = result.get("error", "æœªçŸ¥é”™è¯¯")
                content += f"{i}. **{filename}** - {error}\n"
            content += "\n"
        
        content += f"""## ğŸ¯ ç³»ç»Ÿé…ç½®

- **AIæ¨¡å‹**: {self.model}
- **æœ€å¤§æ–‡æœ¬é•¿åº¦**: {self.max_text_length} å­—ç¬¦
- **æå–é¡µæ•°**: {self.extract_pages if self.extract_pages > 0 else 'å…¨éƒ¨'}
- **è·³è¿‡å·²åˆ†æ**: {'æ˜¯' if self.skip_analyzed else 'å¦'}

## ğŸ“š ç”Ÿæˆæ–‡ä»¶

- **åˆ†ææŠ¥å‘Š**: `{self.summaries_dir.name}/*{self.config.get_output_config()['summary_suffix']}.md`
- **æ–¹æ³•å¡ç‰‡**: `{self.method_cards_dir.name}/*{self.config.get_output_config()['method_card_suffix']}.md`
- **æ‰¹é‡æŠ¥å‘Š**: æœ¬æ–‡ä»¶

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
*AIé©±åŠ¨æ–‡çŒ®åˆ†æç³»ç»Ÿ*
"""
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        self.logger.info(f"æ‰¹é‡åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {report_path.name}")
